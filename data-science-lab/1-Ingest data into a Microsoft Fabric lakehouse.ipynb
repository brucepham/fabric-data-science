{"cells":[{"cell_type":"markdown","source":["# Ingest data into Microsoft Fabric lakehouse using Spark\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3d57de00-a5d2-4021-a31c-3f4875e67b8c"},{"cell_type":"markdown","source":["## **Customer Churn Prediction**\n","Churn prediction modeling techniques attempt to understand the precise customer behaviors and attributes which can help you to predict which customers are more likely to unsubscribe or leave your services"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"dfc01b06-8b56-467c-b7e6-a9f506eb8083"},{"cell_type":"markdown","source":["![Customer Churn](https://az712634.vo.msecnd.net/content/14b2744cf8d6418c87ffddc3f3127242/9502630827244d60a1214f250e3bbca7/ea949e1c6b2d4ed99bd725b20380dca1/effcb4cc2dc24d52999d149f27aa0f26/image)"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"a6c76451-7afd-465c-83b9-10cf1fabc8f1"},{"cell_type":"markdown","source":["### Sample Dataset\n","The sample dataset contains churn status of 10,000 customers along with 14 attributes that include credit score, geographical location (Germany, France, Spain), gender (male, female), age, tenure (years of being bank's customer), account balance, estimated salary, number of products that a customer has purchased through the bank, credit card status (whether a customer has a credit card or not), and active member status (whether an active bank's customer or not).\n","\n","The dataset also includes columns such as row number, customer ID, and customer surname that should have no impact on customer's decision to leave the bank. The event that defines the customer's churn is the closing of the customer's bank account, therefore, the column exit in the dataset refers to customer's abandonment. Since you don't have much context about these attributes, you'll proceed without having background information about the dataset. Your aim is to understand how these attributes contribute to the exit status.\n","\n","Out of the 10,000 customers, only 2037 customers (around 20%) have left the bank. Therefore, given the class imbalance ratio, we recommend generating synthetic data. Moreover, confusion matrix accuracy may not be meaningful for imbalanced classification and it might be better to also measure the accuracy using the Area Under the Precision-Recall Curve (AUPRC).\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"cceb069b-f692-42d7-8855-94bd678f5419"},{"cell_type":"markdown","source":["### Ingest the data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"754fa0a0-e4b9-4849-8eb8-8164b54c6082"},{"cell_type":"markdown","source":["* Make sure you add a lakehouse to the notebook before running it. Failure to do so will result in an error."],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"d4800b43-dee3-441a-a841-b0d8acb79d6f"},{"cell_type":"code","source":["# Azure storage access info for the sample churn.csv data\n","storage_account = \"synapseaisolutionsa\"\n","container = \"public\"\n","dir_name = \"bankcustomerchurn\"\n","file_name = \"churn.csv\"\n","\n","wasbs_path = f\"wasbs://{container}@{storage_account}.blob.core.windows.net/{dir_name}/{file_name}\"\n","\n","df = spark.read.format(\"csv\").option(\"header\", True).option(\"inferSchema\", True).load(wasbs_path).cache()\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"state":"finished","livy_statement_state":"available","session_id":"2dd1d575-6df3-474d-a031-983e1cd91b55","normalized_state":"finished","queued_time":"2025-04-22T15:38:59.5020113Z","session_start_time":"2025-04-22T15:38:59.5030844Z","execution_start_time":"2025-04-22T15:39:12.7417575Z","execution_finish_time":"2025-04-22T15:39:18.0398041Z","parent_msg_id":"79531be3-0cbb-4931-a292-42d504c22a7c"},"text/plain":"StatementMeta(, 2dd1d575-6df3-474d-a031-983e1cd91b55, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"492f9cf9-a9c4-4f9e-821d-7c55faba7569"},{"cell_type":"code","source":["df.count()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"11eb49d6-6e4f-46d1-a9f7-cafaa9f0b880","statement_id":9,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-19T10:24:21.7125658Z","session_start_time":null,"execution_start_time":"2024-03-19T10:24:23.2645684Z","execution_finish_time":"2024-03-19T10:24:24.2362823Z","parent_msg_id":"eafe5a72-5f2c-40ef-870d-0414b18056bb"},"text/plain":"StatementMeta(, 11eb49d6-6e4f-46d1-a9f7-cafaa9f0b880, 9, Finished, Available)"},"metadata":{}},{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"10000"},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c38f9a23-21f5-4db2-a5d6-328f988ffa3c"},{"cell_type":"markdown","source":["### Enable Vorder and Optimized Delta Write*\n","\n","**VOrder**: Fabric includes Microsoft's VOrder engine. VOrder writer optimizes the Delta Lake parquet files resulting in 3x-4x compression improvement and up to 10x performance acceleration over Delta Lake files not optimized using VOrder while still maintaining full Delta Lake and PARQUET format compliance.\n","\n","**Optimize write**: Spark in Fabric includes an Optimize Write feature that reduces the number of files written and targets to increase individual file size of the written data. It dynamically optimizes files during write operations generating files with a default 128 MB size. The target file size may be changed per workload requirements using configurations.\n","These configs can be applied at a session level(as spark.conf.set in a notebook cell) as demonstrated in the following code cell, or at workspace level which is applied automatically to all spark sessions created in the workspace. The workspace level Apache Spark configuration can be set at:\n","\n","**Note**: These are now enabled **by default**. For more details refer to https://learn.microsoft.com/en-us/fabric/data-engineering/delta-optimization-and-v-order?tabs=pyspark\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"16ae358b-729b-441b-b8f8-c75689e6a6f5"},{"cell_type":"code","source":["# spark.conf.set(\"sprk.sql.parquet.vorder.enabled\", \"true\") # VOrder write is enabled by default\n","# spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\") # automatic delta optimized write is enabled by default"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"11eb49d6-6e4f-46d1-a9f7-cafaa9f0b880","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2024-03-19T10:24:21.8512959Z","session_start_time":null,"execution_start_time":"2024-03-19T10:24:24.5710247Z","execution_finish_time":"2024-03-19T10:24:24.908903Z","parent_msg_id":"24abe053-b93b-4f84-924c-823ac896b734"},"text/plain":"StatementMeta(, 11eb49d6-6e4f-46d1-a9f7-cafaa9f0b880, 10, Finished, Available)"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5b11123c-856f-42db-a634-ddc093192d6a"},{"cell_type":"markdown","source":["### Write Spark dataframe to lakehouse delta table"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"7bc15b3a-0068-4f93-94f2-5a5671657dab"},{"cell_type":"code","source":["table_name = \"churn_raw\"\n","df.write.mode(\"overwrite\").format(\"delta\").save(f\"Tables/{table_name}\")\n","print(f\"Spark dataframe saved to delta table: {table_name}\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"state":"finished","livy_statement_state":"available","session_id":"2dd1d575-6df3-474d-a031-983e1cd91b55","normalized_state":"finished","queued_time":"2025-04-22T15:39:27.5868384Z","session_start_time":null,"execution_start_time":"2025-04-22T15:39:27.5882229Z","execution_finish_time":"2025-04-22T15:39:32.2126956Z","parent_msg_id":"d663ef60-59ce-4294-a0cb-5f23503bf4a4"},"text/plain":"StatementMeta(, 2dd1d575-6df3-474d-a031-983e1cd91b55, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Spark dataframe saved to delta table: churn_raw\n"]}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"55616e3a-b8ab-4839-98c4-277146d5ce8f"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"microsoft":{"language":"python","ms_spell_check":{"ms_spell_check_language":"en"},"language_group":"synapse_pyspark"},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"kernel_info":{"name":"synapse_pyspark"},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"cf88674c-2b78-4d41-97cb-70f330d061c1"},{"id":"fe4d57b6-a1a9-41ce-9222-c82a2f3df8fa"}],"default_lakehouse":"fe4d57b6-a1a9-41ce-9222-c82a2f3df8fa","default_lakehouse_name":"data_science_demo","default_lakehouse_workspace_id":"b616bb72-3aaa-46b4-b47a-8ff0254d18b7"}}},"nbformat":4,"nbformat_minor":5}